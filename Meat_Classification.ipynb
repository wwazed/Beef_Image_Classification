{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfTzFij3Am_r"
      },
      "source": [
        "# **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"Available physical devices:\", tf.config.list_physical_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IBWJeb0M_mY5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rx5YiBch_mY6"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
        "\n",
        "# mixed_precision.set_global_policy('mixed_float16')\n",
        " \n",
        "# print(\"Environment set up for ANE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziSWiMMaAwzC"
      },
      "source": [
        "# **Data Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVTF7T1K_mY6"
      },
      "outputs": [],
      "source": [
        "train_path = 'Beef Photo Background Remove/TRAIN/'\n",
        "test_path = 'Beef Photo Background Remove/TEST/'\n",
        "batch_size = 16\n",
        "\n",
        "print(f\"Train path: {train_path}\")\n",
        "print(f\"Test path: {test_path}\")\n",
        "print(f\"Batch size: {batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Ex2w4AAzdO"
      },
      "source": [
        "# **Image resize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x5i15JRZ_mY7"
      },
      "outputs": [],
      "source": [
        "def load_image(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
        "\n",
        "    img.set_shape([None, None, 3])\n",
        "    \n",
        "    img = tf.image.resize(img, (800, 800))\n",
        "\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kGvhIgX1_mY7"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def check_image_files(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.verify()\n",
        "            except (IOError, SyntaxError) as e:\n",
        "                print(f\"Corrupted or invalid image file detected: {file_path}\")\n",
        "\n",
        "check_image_files(train_path)\n",
        "check_image_files(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFIQfhRKBeRx"
      },
      "source": [
        "# **Create a Function to Generate Dataset from Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKf-Ngc4_mY7"
      },
      "outputs": [],
      "source": [
        "def get_dataset_from_directory(directory, batch_size=32, shuffle=True):\n",
        "    # Get class names and create label mapping\n",
        "    class_names = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
        "    class_indices = {name: index for index, name in enumerate(class_names)}\n",
        "    \n",
        "    # Get all image file paths and labels\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        # Skip non-directory files\n",
        "        for file_name in os.listdir(class_dir):\n",
        "            file_path = os.path.join(class_dir, file_name)\n",
        "            if os.path.isfile(file_path):  # Make sure it's a file, not a directory\n",
        "                file_paths.append(file_path)\n",
        "                labels.append(class_indices[class_name])\n",
        "    \n",
        "    # Convert to TensorFlow dataset\n",
        "    file_paths_ds = tf.data.Dataset.from_tensor_slices(file_paths)\n",
        "    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    dataset = tf.data.Dataset.zip((file_paths_ds, labels_ds))\n",
        "    \n",
        "    # Map the load_image function\n",
        "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    # Shuffle, batch, and prefetch\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(file_paths))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    return dataset, class_indices\n",
        "\n",
        "print(\"Dataset loading function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC5GZpBsBmj8"
      },
      "source": [
        "# **Load Training and Testing Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tNNnSlg_mY7"
      },
      "outputs": [],
      "source": [
        "train_dataset, class_indices = get_dataset_from_directory(train_path, batch_size=batch_size, shuffle=True)\n",
        "test_dataset, _ = get_dataset_from_directory(test_path, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Classes found: {class_indices}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVKAMs1OBq0d"
      },
      "source": [
        "# **Update the Model Input to Handle Variable Sizes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WyCugxt_mY7"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(800, 800, 3))\n",
        "\n",
        "for layer in base_model.layers[-100:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(class_indices), activation='softmax', dtype='float32')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "print(\"Model architecture built.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvgGh02S_mY8"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=3e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfK3YwJY_mY8"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1)\n",
        "\n",
        "print(\"Callbacks for training defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqdC1QVuBu2e"
      },
      "source": [
        "# **Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W83rTBt_mY8"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=5,\n",
        "    validation_data=test_dataset,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Model training completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('Beef_Classification.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irHkWO-yBzSR"
      },
      "source": [
        "# **Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbU9Z1cH_mY8"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "predictions = model.predict(test_dataset)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_indices.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2MOohLPB2HV"
      },
      "source": [
        "# **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKcdhWfP_mY8"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_indices.keys(),\n",
        "            yticklabels=class_indices.keys())\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
