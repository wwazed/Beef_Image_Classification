# Beef Image Classification with TensorFlow
This repository contains a notebook for meat classification using a deep learning approach with TensorFlow. The main purpose of the notebook is to build a model based on ResNet50 architecture to classify fresh and rotten meat from images.
## Key Features
The notebook focuses on building a meat classification model using TensorFlow and Keras. It begins by importing necessary libraries and setting up paths for training and testing datasets. A TensorFlow dataset is generated for efficient data loading, followed by constructing a model based on a pre-trained ResNet50 architecture, which is fine-tuned with additional layers to match the classification task. The model is compiled, trained with early stopping and learning rate reduction for optimal performance, and saved upon completion. Finally, the model is evaluated on the test dataset, and results are visualized through a classification report and confusion matrix to understand the performance across the two meat classes.
## Data Preprocessing
The data preprocessing procedure begins by defining the file paths for the training and testing datasets, which are structured in directories containing subdirectories for each meat class. It is worth saying, the background of each image are removed before. To ensure uniformity, all images are resized to a dimension of 800x800 pixels. This resizing is essential as it provides consistency in image input size, a requirement for neural networks. Additionally, a function is implemented using the **PIL** library to validate each image file in the directories. This verification step helps identify and handle any corrupted or invalid images that could potentially disrupt the training process.

Following the validation and resizing, the notebook creates TensorFlow datasets for efficient data handling during model training. A custom function maps each image path to its corresponding label and creates TensorFlow datasets for both training and testing, with the option to shuffle and batch the images. Each image is read, decoded, resized, and normalized to a float32 type to ensure compatibility with the model. The datasets are structured and pre-fetched for optimal performance, making the data readily available for the training and evaluation phases of the model.
## Model Construction & Compilation
This section leverages transfer learning by using the **ResNet50** architecture, which is pre-trained on the ImageNet dataset. The base model is set to exclude its original classification layers (include_top=False), allowing for customization of the network's output for the specific task of meat classification. An input shape of (800, 800, 3) is defined to match the resized image dimensions. To adapt ResNet50 for this task, only the final 100 layers are set to be trainable, enabling fine-tuning while retaining most of the pre-trained features. On top of the base model, additional layers are added: **Global Average Pooling, Dropout for regularization, Dense layers with relu activations and L2 regularization**, and **Batch Normalization** layers to improve model generalization. The final layer uses a softmax activation with a number of neurons corresponding to the classes of meat in the dataset.

For model compilation, the optimizer chosen is **Adam**, with a learning rate of 3e-4 to ensure smooth convergence. The loss function is set to sparse_categorical_crossentropy, which is suitable for multi-class classification with integer labels. The model also tracks accuracy as a performance metric during training. To further enhance training, callbacks like early stopping and learning rate reduction on plateau are defined. These callbacks monitor the validation loss, stopping training when performance ceases to improve and dynamically adjusting the learning rate when the loss plateaus. This setup aims to achieve the best performance with efficient training while preventing overfitting.
## Model Evaluation
The trained model is evaluated bt testing on the prepared test dataset to calculate the overall accuracy and loss. Predictions are made on the test data, and the true labels are compared to these predictions. The modelâ€™s performance is assessed using a classification report generated by scikit-learn, which provides key metrics such as precision, recall, and F1-score for each class. The testing accuracy is achieved 99%, while precision, recall and F1-score have hit 100% for both fresh and rotten classes. Additionally, a confusion matrix is visualized to offer a detailed view of true versus predicted labels, allowing for easy identification of any misclassifications between similar classes.
## Requirements
1. Python 3.12
2. TensorFlow 2.x & Keras
3. PIL (Pillow)
4. Seaborn
5. NumPy
6. CUDA 11.2 (Nvidia) or ANE Support (Apple)
## Contributing
Contributions are welcome! Feel free to open issues or submit pull requests.
## License
This project is licensed under the Apache 2.0 License - see the LICENSE file for details.
